{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# Artificial Neural Network (ANN)\n",
    "\n",
    "Work by: Raghavendra Tapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZaTwK7ojXr2F",
    "outputId": "0b27a96d-d11a-43e8-ab4b-87c1f01896fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset\n",
    "\n",
    "* x - all the features except exited column\n",
    "* y - value to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "x = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding Categorical Data\n",
    "\n",
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "x[:, 2] = le.fit_transform(x[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "x = np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Building the ANN\n",
    "\n",
    "How many neurons to choose is a trial and error process in deep learning.\n",
    "\n",
    "* **1st layer:** `rectifier` activation function, `6` neurons\n",
    "* **2nd layer:** `rectifier` activation function, `6` neurons\n",
    "* **Output layer:** `sigmoid` activation function,  `1` neuron, because the variable we are trying to predict is `binary classification` problem.\n",
    "\n",
    "i.e. Whether or not the customer leaves the bank. (Yes or No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Training the ANN\n",
    "\n",
    "* `Adam optimizer`: Adaptive Moment Estimation or Adam optimizer combines two gradient descent methodologies. Adaptive Moment Estimation is an algorithm for optimization technique for gradient descent. The method is really efficient when working with large problem involving a lot of data or parameters.\n",
    "\n",
    "* `Binary Cross-Entropy`: Cross-entropy is a measure of the difference between two probability distributions for a given random variable or set of events. Since we’re trying to compute a loss, we need to penalize bad predictions. If the probability associated with the true class is 1.0, we need its loss to be zero. Conversely, if that probability is low, say, 0.01, we need its loss to be huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set\n",
    "\n",
    "* Batch gradient descent is faster to compute. Usually batch size is taken to be 32.\n",
    "* One epoch consists of one full training cycle on the training set. Once every sample in the set is seen, you start again - marking the beginning of the 2nd epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nHZ-LKv_ZRb3",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3358 - accuracy: 0.8650\n",
      "Epoch 2/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3339 - accuracy: 0.8644\n",
      "Epoch 3/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8671\n",
      "Epoch 4/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3335 - accuracy: 0.8636\n",
      "Epoch 5/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8671\n",
      "Epoch 6/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8670\n",
      "Epoch 7/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8666\n",
      "Epoch 8/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3325 - accuracy: 0.8643\n",
      "Epoch 9/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3323 - accuracy: 0.8639\n",
      "Epoch 10/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3317 - accuracy: 0.8668\n",
      "Epoch 11/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3321 - accuracy: 0.8648\n",
      "Epoch 12/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3317 - accuracy: 0.8649\n",
      "Epoch 13/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8629\n",
      "Epoch 14/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8645\n",
      "Epoch 15/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8677\n",
      "Epoch 16/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3317 - accuracy: 0.8664\n",
      "Epoch 17/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8649\n",
      "Epoch 18/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8656\n",
      "Epoch 19/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8665\n",
      "Epoch 20/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8640\n",
      "Epoch 21/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3308 - accuracy: 0.8662\n",
      "Epoch 22/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3304 - accuracy: 0.8654\n",
      "Epoch 23/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8643\n",
      "Epoch 24/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3306 - accuracy: 0.8656\n",
      "Epoch 25/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8652\n",
      "Epoch 26/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8654\n",
      "Epoch 27/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8655\n",
      "Epoch 28/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3304 - accuracy: 0.8652\n",
      "Epoch 29/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3306 - accuracy: 0.8635\n",
      "Epoch 30/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8662\n",
      "Epoch 31/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8649\n",
      "Epoch 32/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3292 - accuracy: 0.8652\n",
      "Epoch 33/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3299 - accuracy: 0.8654\n",
      "Epoch 34/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3293 - accuracy: 0.8652\n",
      "Epoch 35/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8675\n",
      "Epoch 36/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8654\n",
      "Epoch 37/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3302 - accuracy: 0.8640\n",
      "Epoch 38/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3298 - accuracy: 0.8645\n",
      "Epoch 39/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3296 - accuracy: 0.8627\n",
      "Epoch 40/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8643\n",
      "Epoch 41/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3296 - accuracy: 0.8640\n",
      "Epoch 42/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3299 - accuracy: 0.8649\n",
      "Epoch 43/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8675\n",
      "Epoch 44/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8639\n",
      "Epoch 45/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3286 - accuracy: 0.8650\n",
      "Epoch 46/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3294 - accuracy: 0.8659\n",
      "Epoch 47/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.8652\n",
      "Epoch 48/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3289 - accuracy: 0.8659\n",
      "Epoch 49/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3294 - accuracy: 0.8650\n",
      "Epoch 50/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3293 - accuracy: 0.8640\n",
      "Epoch 51/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8643\n",
      "Epoch 52/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3289 - accuracy: 0.8644: 0s - loss:\n",
      "Epoch 53/100\n",
      "667/667 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.8649 ETA: 0s - loss: 0.331 - 2s 3ms/step - loss: 0.3289 - accuracy: 0.8648\n",
      "Epoch 54/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3288 - accuracy: 0.8664\n",
      "Epoch 55/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3291 - accuracy: 0.8656\n",
      "Epoch 56/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3290 - accuracy: 0.8650\n",
      "Epoch 57/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.8650\n",
      "Epoch 58/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3290 - accuracy: 0.8652\n",
      "Epoch 59/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.8658\n",
      "Epoch 60/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8650\n",
      "Epoch 61/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8654\n",
      "Epoch 62/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3282 - accuracy: 0.8661\n",
      "Epoch 63/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8659\n",
      "Epoch 64/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3285 - accuracy: 0.8652\n",
      "Epoch 65/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8671\n",
      "Epoch 67/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3280 - accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3284 - accuracy: 0.8644\n",
      "Epoch 69/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8675\n",
      "Epoch 70/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.8648\n",
      "Epoch 71/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3272 - accuracy: 0.8649\n",
      "Epoch 72/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3281 - accuracy: 0.8656\n",
      "Epoch 73/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3277 - accuracy: 0.8651\n",
      "Epoch 74/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8668\n",
      "Epoch 75/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8636\n",
      "Epoch 76/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3280 - accuracy: 0.8658\n",
      "Epoch 77/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8656\n",
      "Epoch 78/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8656\n",
      "Epoch 79/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3278 - accuracy: 0.8633\n",
      "Epoch 80/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3277 - accuracy: 0.8680\n",
      "Epoch 81/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3277 - accuracy: 0.8683\n",
      "Epoch 82/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3274 - accuracy: 0.8664\n",
      "Epoch 83/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3280 - accuracy: 0.8666\n",
      "Epoch 84/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3269 - accuracy: 0.8673\n",
      "Epoch 85/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3272 - accuracy: 0.8651\n",
      "Epoch 86/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3277 - accuracy: 0.8639\n",
      "Epoch 87/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3269 - accuracy: 0.8670\n",
      "Epoch 88/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3268 - accuracy: 0.8669\n",
      "Epoch 89/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3277 - accuracy: 0.8660\n",
      "Epoch 90/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3272 - accuracy: 0.8665\n",
      "Epoch 91/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3269 - accuracy: 0.8661\n",
      "Epoch 92/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3278 - accuracy: 0.8658\n",
      "Epoch 93/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3280 - accuracy: 0.8654\n",
      "Epoch 94/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3274 - accuracy: 0.8650\n",
      "Epoch 95/100\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 0.3278 - accuracy: 0.8648\n",
      "Epoch 96/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3270 - accuracy: 0.8633\n",
      "Epoch 97/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3275 - accuracy: 0.8648\n",
      "Epoch 98/100\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.3272 - accuracy: 0.8659\n",
      "Epoch 99/100\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.3272 - accuracy: 0.8665\n",
      "Epoch 100/100\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.3274 - accuracy: 0.8659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11dad1c2bb0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 100/100\n",
    "667/667 [==============================] - 3s 4ms/step - loss: 0.3274 - accuracy: 0.8659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84QFoqGYeXHL"
   },
   "source": [
    "### Predicting the result of a single observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGjx94g2n7OV"
   },
   "source": [
    "Therefore, our ANN model predicts that this customer stays in the bank!\n",
    "\n",
    "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
    "\n",
    "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns.\n",
    "\n",
    "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
    "\n",
    "* Geography: France \n",
    "* Credit Score: 600\n",
    "* Gender: Male\n",
    "* Age: 40 years old\n",
    "* Tenure: 3 years\n",
    "* Balance: \\$ 60000, \n",
    "* Number of Products: 2, \n",
    "* Does this customer have a credit card ? Yes\n",
    "* Is this customer an Active Member: Yes\n",
    "* Estimated Salary: \\$ 50000\n",
    "\n",
    "So, should we say goodbye to that customer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assumption: Threshold Probability = 0.5\n",
    "* Less than 0.5 = False. The person will not leave the bank\n",
    "* More than 0.5 = True. The person will leave the bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07359219]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Geography: Spain ---> [0,1,0]\n",
    "* Credit Score: 750\n",
    "* Gender: Female\n",
    "* Age: 35 years old\n",
    "* Tenure: 10 years\n",
    "* Balance: \\$ 70000, \n",
    "* Number of Products: 4, \n",
    "* Does this customer have a credit card ? Yes\n",
    "* Is this customer an Active Member: No\n",
    "* Estimated Salary: \\$ 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "text",
    "id": "CGRo3eacgDdC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[0, 1, 0, 750, 1, 35, 10, 70000, 4, 1, 0, 50000]])) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8739985]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[0, 1, 0, 750, 1, 35, 10, 70000, 4, 1, 0, 50000]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1500   95]\n",
      " [ 183  222]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.861"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Function that Plots a confusion matrix using seaborn's heatmap()\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize = (5,5))\n",
    "    ax = sns.heatmap(conf_mat, annot=True, cbar = False, cmap=\"Greens\")\n",
    "    plt.xlabel(\"True label\")\n",
    "    plt.ylabel(\"Predicted label\");\n",
    "    \n",
    "plot_conf_mat(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
